{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27d5d0bf-b9aa-4608-89b5-b64c5524e171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/plasticc/transient_features.csv', '../results')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Quantum imports (Qiskit 1.x + qiskit-machine-learning)\n",
    "from qiskit.circuit.library import ZZFeatureMap, TwoLocal\n",
    "from qiskit.primitives import Estimator\n",
    "from qiskit_algorithms.optimizers import COBYLA\n",
    "\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = os.path.join(\"..\", \"data\", \"plasticc\")\n",
    "FEATURES_PATH = os.path.join(DATA_DIR, \"transient_features.csv\")\n",
    "\n",
    "RESULTS_DIR = os.path.join(\"..\", \"results\")\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "FEATURES_PATH, RESULTS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f197fbfa-e434-4ebc-b972-af8431dd1cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transient_id</th>\n",
       "      <th>n_points</th>\n",
       "      <th>flux_min</th>\n",
       "      <th>flux_max</th>\n",
       "      <th>delta_flux</th>\n",
       "      <th>flux_mean</th>\n",
       "      <th>flux_std</th>\n",
       "      <th>time_span</th>\n",
       "      <th>max_slope</th>\n",
       "      <th>min_slope</th>\n",
       "      <th>mean_slope</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73799799</td>\n",
       "      <td>146</td>\n",
       "      <td>-71.079659</td>\n",
       "      <td>174.403397</td>\n",
       "      <td>245.483056</td>\n",
       "      <td>6.333829</td>\n",
       "      <td>25.600407</td>\n",
       "      <td>1088.9187</td>\n",
       "      <td>396.000641</td>\n",
       "      <td>-79.409779</td>\n",
       "      <td>3.106681</td>\n",
       "      <td>SNIa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>215282</td>\n",
       "      <td>352</td>\n",
       "      <td>-21.821419</td>\n",
       "      <td>26.039886</td>\n",
       "      <td>47.861305</td>\n",
       "      <td>1.982695</td>\n",
       "      <td>5.601848</td>\n",
       "      <td>873.7903</td>\n",
       "      <td>2266.541688</td>\n",
       "      <td>-2429.961380</td>\n",
       "      <td>-23.766219</td>\n",
       "      <td>SNIa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92999561</td>\n",
       "      <td>128</td>\n",
       "      <td>-56.247101</td>\n",
       "      <td>220.577240</td>\n",
       "      <td>276.824341</td>\n",
       "      <td>5.884043</td>\n",
       "      <td>35.070857</td>\n",
       "      <td>913.7473</td>\n",
       "      <td>1563.930964</td>\n",
       "      <td>-58.885288</td>\n",
       "      <td>14.755975</td>\n",
       "      <td>SNIa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19866</td>\n",
       "      <td>351</td>\n",
       "      <td>-11.846063</td>\n",
       "      <td>270.410736</td>\n",
       "      <td>282.256799</td>\n",
       "      <td>20.666038</td>\n",
       "      <td>49.216990</td>\n",
       "      <td>853.7060</td>\n",
       "      <td>13188.285782</td>\n",
       "      <td>-13483.200137</td>\n",
       "      <td>-39.150423</td>\n",
       "      <td>SNIa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68637164</td>\n",
       "      <td>106</td>\n",
       "      <td>-122.754425</td>\n",
       "      <td>119.619064</td>\n",
       "      <td>242.373489</td>\n",
       "      <td>3.275453</td>\n",
       "      <td>24.372910</td>\n",
       "      <td>912.7714</td>\n",
       "      <td>407.938275</td>\n",
       "      <td>-1304.584846</td>\n",
       "      <td>-12.743792</td>\n",
       "      <td>SNIa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transient_id  n_points    flux_min    flux_max  delta_flux  flux_mean  \\\n",
       "0      73799799       146  -71.079659  174.403397  245.483056   6.333829   \n",
       "1        215282       352  -21.821419   26.039886   47.861305   1.982695   \n",
       "2      92999561       128  -56.247101  220.577240  276.824341   5.884043   \n",
       "3         19866       351  -11.846063  270.410736  282.256799  20.666038   \n",
       "4      68637164       106 -122.754425  119.619064  242.373489   3.275453   \n",
       "\n",
       "    flux_std  time_span     max_slope     min_slope  mean_slope label  \n",
       "0  25.600407  1088.9187    396.000641    -79.409779    3.106681  SNIa  \n",
       "1   5.601848   873.7903   2266.541688  -2429.961380  -23.766219  SNIa  \n",
       "2  35.070857   913.7473   1563.930964    -58.885288   14.755975  SNIa  \n",
       "3  49.216990   853.7060  13188.285782 -13483.200137  -39.150423  SNIa  \n",
       "4  24.372910   912.7714    407.938275  -1304.584846  -12.743792  SNIa  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = pd.read_csv(FEATURES_PATH)\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a2ce3ca-d5c0-4092-a694-929b9fc688b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((600, 3), (600,), (array([0, 1]), array([300, 300])))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the engineered features (update if you renamed things)\n",
    "selected_features = [\"delta_flux\", \"flux_std\", \"time_span\"]\n",
    "\n",
    "for f in selected_features:\n",
    "    if f not in features_df.columns:\n",
    "        raise ValueError(f\"Feature {f} not found in dataframe columns: {features_df.columns.tolist()}\")\n",
    "\n",
    "X = features_df[selected_features].values\n",
    "y_str = features_df[\"label\"].values\n",
    "\n",
    "label_mapping = {\"SNII\": 0, \"SNIa\": 1}\n",
    "y = np.array([label_mapping[val] for val in y_str])\n",
    "\n",
    "X.shape, y.shape, np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d33eab3-d447-41ba-83ac-f0c26de3699c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((480, 3), (120, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc44d340-deab-4fd5-b7f2-842ed376ac50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.21004759, -0.17150886, -0.59250258],\n",
       "       [-0.25062977, -0.2312758 , -1.41832599],\n",
       "       [ 0.09977606,  0.16031387, -0.8012525 ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Map to angles in [-œÄ/2, œÄ/2]\n",
    "X_train_angles = (np.pi / 2.0) * X_train_scaled\n",
    "X_test_angles = (np.pi / 2.0) * X_test_scaled\n",
    "\n",
    "X_train_angles[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca8bc08a-f3cd-4852-894a-93ab73660ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = X_train_angles.shape[1]\n",
    "num_qubits = num_features\n",
    "\n",
    "num_qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61b2dfa7-2de9-4ce5-8380-a9310cea86e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature map: encodes classical features into rotations + entanglement\n",
    "feature_map = ZZFeatureMap(\n",
    "    feature_dimension=num_features,\n",
    "    reps=1,          # you can try 2 later\n",
    "    entanglement=\"linear\"\n",
    ")\n",
    "\n",
    "# Ansatz: trainable part of the circuit\n",
    "ansatz = TwoLocal(\n",
    "    num_qubits=num_qubits,\n",
    "    reps=2,          # circuit depth ‚Äì can tune later\n",
    "    rotation_blocks=[\"ry\", \"rz\"],\n",
    "    entanglement_blocks=\"cz\",\n",
    "    entanglement=\"linear\"\n",
    ")\n",
    "\n",
    "# Full variational circuit = feature_map -> ansatz\n",
    "from qiskit import QuantumCircuit\n",
    "\n",
    "circuit = QuantumCircuit(num_qubits)\n",
    "circuit.compose(feature_map, inplace=True)\n",
    "circuit.compose(ansatz, inplace=True)\n",
    "\n",
    "# Use text drawer to avoid extra dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cf191fd-bfe2-4b40-b769-ebac7eec56a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4j/986s_f794zq87n31mh_7ls200000gn/T/ipykernel_80587/2743393232.py:1: DeprecationWarning: The class ``qiskit.primitives.estimator.Estimator`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseEstimatorV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `Estimator` class is `StatevectorEstimator`.\n",
      "  estimator = Estimator()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 18)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = Estimator()\n",
    "\n",
    "# Input parameters = classical feature angles\n",
    "input_params = list(feature_map.parameters)\n",
    "\n",
    "# Trainable parameters = ansatz weights\n",
    "weight_params = list(ansatz.parameters)\n",
    "\n",
    "len(input_params), len(weight_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "803d2724-6f83-4837-bbc6-9a2d6b2129a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4j/986s_f794zq87n31mh_7ls200000gn/T/ipykernel_80587/974032110.py:1: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
      "  qnn = EstimatorQNN(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<qiskit_machine_learning.neural_networks.estimator_qnn.EstimatorQNN at 0x1782ccdf0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qnn = EstimatorQNN(\n",
    "    estimator=estimator,\n",
    "    circuit=circuit,\n",
    "    input_params=input_params,\n",
    "    weight_params=weight_params,\n",
    ")\n",
    "\n",
    "qnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4982b5e-89d1-45ca-be33-43c0aebbfc42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<qiskit_machine_learning.algorithms.classifiers.neural_network_classifier.NeuralNetworkClassifier at 0x179fb6c70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = COBYLA(maxiter=80)  # you can increase later if you want\n",
    "\n",
    "q_clf = NeuralNetworkClassifier(\n",
    "    neural_network=qnn,\n",
    "    optimizer=optimizer,\n",
    "    one_hot=False,      # binary labels 0/1\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "q_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "093b71e9-cdce-4afa-bf3a-ca8d97b13547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.4 s, sys: 1.31 s, total: 55.7 s\n",
      "Wall time: 1min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<qiskit_machine_learning.algorithms.classifiers.neural_network_classifier.NeuralNetworkClassifier at 0x179fb6c70>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "q_clf.fit(X_train_angles, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f490497-9ca9-4113-bf5b-ad82cf76437b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw quantum preds (unique): [-1.  1.]\n",
      "Mapped preds (unique): [0 1]\n",
      "y_proba_q shape: (120, 1)\n",
      "score min/max: -0.57778967024171 0.8096137754110566\n",
      "\n",
      "Quantum (EstimatorQNN) accuracy: 0.475\n",
      "Quantum (EstimatorQNN) AUC:      0.459\n",
      "\n",
      "Classification report (Quantum):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    SNII (0)       0.20      0.02      0.03        60\n",
      "    SNIa (1)       0.49      0.93      0.64        60\n",
      "\n",
      "    accuracy                           0.47       120\n",
      "   macro avg       0.34      0.48      0.34       120\n",
      "weighted avg       0.34      0.47      0.34       120\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1, 59],\n",
       "       [ 4, 56]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# ---- 1. Get raw quantum predictions ----\n",
    "y_pred_raw = q_clf.predict(X_test_angles)\n",
    "print(\"Raw quantum preds (unique):\", np.unique(y_pred_raw))\n",
    "\n",
    "# Map raw labels to {0,1}\n",
    "# Assume <= 0 -> class 0 (SNII), > 0 -> class 1 (SNIa)\n",
    "y_pred_q = np.where(y_pred_raw <= 0, 0, 1)\n",
    "print(\"Mapped preds (unique):\", np.unique(y_pred_q))\n",
    "\n",
    "# ---- 2. Get quantum \"probabilities\"/scores ----\n",
    "y_proba_q = q_clf.predict_proba(X_test_angles)  # shape (n_samples, 1) in your case\n",
    "print(\"y_proba_q shape:\", y_proba_q.shape)\n",
    "\n",
    "# Flatten to (n_samples,) ‚Äì works for (n,1) or (n,)\n",
    "scores = y_proba_q.ravel()\n",
    "print(\"score min/max:\", scores.min(), scores.max())\n",
    "\n",
    "# ---- 3. Metrics ----\n",
    "q_acc = accuracy_score(y_test, y_pred_q)\n",
    "q_auc = roc_auc_score(y_test, scores)  # use 1D scores for AUC\n",
    "\n",
    "print(f\"\\nQuantum (EstimatorQNN) accuracy: {q_acc:.3f}\")\n",
    "print(f\"Quantum (EstimatorQNN) AUC:      {q_auc:.3f}\\n\")\n",
    "\n",
    "print(\"Classification report (Quantum):\")\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        y_pred_q,\n",
    "        labels=[0, 1],  # explicitly say which labels we care about\n",
    "        target_names=[\"SNII (0)\", \"SNIa (1)\"],\n",
    "        zero_division=0,\n",
    "    )\n",
    ")\n",
    "\n",
    "cm_q = confusion_matrix(y_test, y_pred_q, labels=[0, 1])\n",
    "cm_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b11886d-dd7c-4f6f-b601-3401bb658381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n",
      "======================================================================\n",
      "QUANTUM ML - OUTLIER-ROBUST VERSION\n",
      "======================================================================\n",
      "\n",
      "Features path: ../data/plasticc/transient_features.csv\n",
      "Results dir: ../results\n",
      "\n",
      "Loaded 600 samples\n",
      "Available columns: ['transient_id', 'n_points', 'flux_min', 'flux_max', 'delta_flux', 'flux_mean', 'flux_std', 'time_span', 'max_slope', 'min_slope', 'mean_slope', 'label']\n",
      "\n",
      "======================================================================\n",
      "FEATURE ANALYSIS BY CLASS\n",
      "======================================================================\n",
      "\n",
      "Feature means by class:\n",
      "         n_points   flux_min    flux_max  delta_flux  flux_mean   flux_std  \\\n",
      "label                                                                        \n",
      "SNII   178.800000 -53.312604  451.000899  504.313503  34.258654  93.670573   \n",
      "SNIa   203.193333 -50.560370  336.772262  387.332632  17.672213  57.700657   \n",
      "\n",
      "        time_span    max_slope    min_slope  mean_slope  \n",
      "label                                                    \n",
      "SNII   944.824472  7891.975583 -6892.593720   34.580906  \n",
      "SNIa   938.105175  4311.663322 -4353.754888  -26.541751  \n",
      "\n",
      "Feature standard deviations by class:\n",
      "         n_points   flux_min     flux_max   delta_flux   flux_mean  \\\n",
      "label                                                                \n",
      "SNII    91.673005  29.223320  2547.228024  2546.162627  206.538891   \n",
      "SNIa   100.939082  42.742431  1410.109724  1411.948202   58.291624   \n",
      "\n",
      "         flux_std  time_span     max_slope     min_slope  mean_slope  \n",
      "label                                                                 \n",
      "SNII   571.193469  96.886909  70951.100410  61044.794058  193.917822  \n",
      "SNIa   206.721960  97.794451   8193.526735  10592.756847  167.486965  \n",
      "\n",
      "Coefficient of Variation (lower is more stable):\n",
      "       n_points  flux_min  flux_max  delta_flux  flux_mean  flux_std  \\\n",
      "label                                                                  \n",
      "SNII   0.512713  0.548150  5.647944    5.048769   6.028809  6.097897   \n",
      "SNIa   0.496764  0.845374  4.187131    3.645312   3.298490  3.582662   \n",
      "\n",
      "       time_span  max_slope  min_slope  mean_slope  \n",
      "label                                               \n",
      "SNII    0.102545   8.990284   8.856578    5.607656  \n",
      "SNIa    0.104247   1.900317   2.433016    6.310321  \n",
      "\n",
      "======================================================================\n",
      "SELECTING ROBUST FEATURES\n",
      "======================================================================\n",
      "\n",
      "Selected features: ['flux_std', 'flux_mean', 'time_span']\n",
      "\n",
      "Raw data shape: (600, 3)\n",
      "Class distribution: {np.int64(0): np.int64(300), np.int64(1): np.int64(300)}\n",
      "\n",
      "======================================================================\n",
      "RAW FEATURE STATISTICS (BEFORE SCALING)\n",
      "======================================================================\n",
      "\n",
      "flux_std:\n",
      "  Min:    2.8928\n",
      "  Max:    9821.2519\n",
      "  Mean:   75.6856\n",
      "  Median: 30.9794\n",
      "  Std:    429.1928\n",
      "  25%:    20.7587\n",
      "  75%:    53.7573\n",
      "  99%:    471.2337\n",
      "\n",
      "flux_mean:\n",
      "  Min:    -0.7728\n",
      "  Max:    3528.6600\n",
      "  Mean:   25.9654\n",
      "  Median: 8.5591\n",
      "  Std:    151.7239\n",
      "  25%:    4.6557\n",
      "  75%:    18.0159\n",
      "  99%:    189.3574\n",
      "\n",
      "time_span:\n",
      "  Min:    755.9755\n",
      "  Max:    1094.0016\n",
      "  Mean:   941.4648\n",
      "  Median: 898.7065\n",
      "  Std:    97.2374\n",
      "  25%:    856.4007\n",
      "  75%:    1067.5387\n",
      "  99%:    1092.0558\n",
      "\n",
      "======================================================================\n",
      "APPLYING OUTLIER-ROBUST SCALING\n",
      "======================================================================\n",
      "Feature 0 (flux_std) clipped to [3.3105, 471.2337]\n",
      "Feature 1 (flux_mean) clipped to [0.2505, 189.3574]\n",
      "Feature 2 (time_span) clipped to [848.8198, 1092.0558]\n",
      "  Feature 0 has large dynamic range (141.3), applying log transform\n",
      "  Feature 1 has large dynamic range (754.9), applying log transform\n",
      "\n",
      "Train: (480, 3), Test: (120, 3)\n",
      "Train class distribution: {np.int64(0): np.int64(240), np.int64(1): np.int64(240)}\n",
      "Test class distribution: {np.int64(0): np.int64(60), np.int64(1): np.int64(60)}\n",
      "\n",
      "======================================================================\n",
      "SCALING TO QUANTUM ANGLES\n",
      "======================================================================\n",
      "\n",
      "Scaled feature ranges (train):\n",
      "  Min:    [0. 0. 0.]\n",
      "  Max:    [3.14159265 3.14159265 3.14159265]\n",
      "  Mean:   [1.56574391 1.21378918 1.1920163 ]\n",
      "  Median: [1.52461728 1.11223822 0.6444788 ]\n",
      "\n",
      "Feature distribution check:\n",
      "  flux_std: mean=1.566, median=1.525\n",
      "    ‚úì Good: Feature centered around œÄ/2\n",
      "  flux_mean: mean=1.214, median=1.112\n",
      "    ‚úì Good: Feature centered around œÄ/2\n",
      "  time_span: mean=1.192, median=0.644\n",
      "    ‚úì Good: Feature centered around œÄ/2\n",
      "\n",
      "======================================================================\n",
      "BUILDING 3-QUBIT QUANTUM CIRCUIT\n",
      "======================================================================\n",
      "\n",
      "Circuit statistics:\n",
      "  Depth: 2\n",
      "  Total parameters: 27\n",
      "  Input params: 3\n",
      "  Trainable params: 24\n",
      "\n",
      "EstimatorQNN created\n",
      "  Input dimension: 3\n",
      "  Trainable weights: 24\n",
      "\n",
      "Quantum classifier: COBYLA(maxiter=300)\n",
      "\n",
      "======================================================================\n",
      "TRAINING QUANTUM MODEL (this may take 5-7 minutes)\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4j/986s_f794zq87n31mh_7ls200000gn/T/ipykernel_80587/805784770.py:262: DeprecationWarning: The class ``qiskit.primitives.estimator.Estimator`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseEstimatorV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `Estimator` class is `StatevectorEstimator`.\n",
      "  estimator = Estimator()\n",
      "/var/folders/4j/986s_f794zq87n31mh_7ls200000gn/T/ipykernel_80587/805784770.py:267: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
      "  qnn = EstimatorQNN(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Training completed in 375.8s (6.3 min)\n",
      "\n",
      "======================================================================\n",
      "EVALUATION\n",
      "======================================================================\n",
      "\n",
      "Raw predictions: [-1.  1.]\n",
      "Binary predictions: [0 1]\n",
      "Prediction counts: {np.int64(0): np.int64(11), np.int64(1): np.int64(109)}\n",
      "Score range: [-0.5372, 0.8517]\n",
      "Score mean: 0.3503, std: 0.2717\n",
      "\n",
      "======================================================================\n",
      "RESULTS\n",
      "======================================================================\n",
      "\n",
      "üéØ Accuracy: 50.8% (0.508)\n",
      "üìä AUC:      44.3% (0.443)\n",
      "\n",
      "üìà Random baseline: 50.0%\n",
      "üìà Improvement: 0.8% (+0.008)\n",
      "\n",
      "üìä Classical baseline: 75.0%\n",
      "üìä Gap to classical: -24.2% (-0.242)\n",
      "\n",
      "======================================================================\n",
      "CLASSIFICATION REPORT\n",
      "======================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    SNII (0)       0.55      0.10      0.17        60\n",
      "    SNIa (1)       0.50      0.92      0.65        60\n",
      "\n",
      "    accuracy                           0.51       120\n",
      "   macro avg       0.53      0.51      0.41       120\n",
      "weighted avg       0.53      0.51      0.41       120\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted\n",
      "              SNII  SNIa\n",
      "Actual SNII     6    54\n",
      "       SNIa     5    55\n",
      "\n",
      "Sensitivity (recall for SNIa): 91.7%\n",
      "Specificity (recall for SNII): 10.0%\n",
      "Balanced accuracy: 50.8%\n",
      "\n",
      "Results saved to: ../results/plasticc_quantum_results_robust.json\n",
      "\n",
      "======================================================================\n",
      "FINAL ASSESSMENT\n",
      "======================================================================\n",
      "\n",
      "‚ö†Ô∏è  Model performed at random level (<52%)\n",
      "\n",
      "Possible issues:\n",
      "  1. Features still have poor separation\n",
      "  2. Circuit might need different architecture\n",
      "  3. Dataset too small for quantum advantage\n",
      "  4. Try different feature combinations\n",
      "\n",
      "======================================================================\n",
      "COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "Next steps:\n",
      "  1. Document results in README\n",
      "  2. Compare quantum vs classical approaches\n",
      "  3. Discuss learnings about quantum ML limitations\n",
      "  4. Consider trying different feature sets if time permits\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 03_quantum_classifier.ipynb - OPTION A: OUTLIER-ROBUST VERSION\n",
    "# Quantum ML for PLAsTiCC Transient Classification\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "# Quantum imports (Qiskit 1.x + qiskit-machine-learning)\n",
    "from qiskit.circuit.library import ZZFeatureMap, TwoLocal\n",
    "from qiskit.primitives import Estimator\n",
    "from qiskit_algorithms.optimizers import COBYLA\n",
    "\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
    "\n",
    "# ============================================================================\n",
    "# 1. SETUP PATHS\n",
    "# ============================================================================\n",
    "\n",
    "DATA_DIR = os.path.join(\"..\", \"data\", \"plasticc\")\n",
    "FEATURES_PATH = os.path.join(DATA_DIR, \"transient_features.csv\")\n",
    "\n",
    "RESULTS_DIR = os.path.join(\"..\", \"results\")\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"QUANTUM ML - OUTLIER-ROBUST VERSION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nFeatures path: {FEATURES_PATH}\")\n",
    "print(f\"Results dir: {RESULTS_DIR}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. LOAD DATA & ANALYZE FEATURES\n",
    "# ============================================================================\n",
    "\n",
    "features_df = pd.read_csv(FEATURES_PATH)\n",
    "print(f\"Loaded {len(features_df)} samples\")\n",
    "print(f\"Available columns: {features_df.columns.tolist()}\\n\")\n",
    "\n",
    "# Analyze feature statistics to find stable features\n",
    "print(\"=\" * 70)\n",
    "print(\"FEATURE ANALYSIS BY CLASS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "numeric_cols = features_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols.remove('transient_id')  # Remove ID column\n",
    "\n",
    "print(\"\\nFeature means by class:\")\n",
    "feature_stats = features_df.groupby('label')[numeric_cols].mean()\n",
    "print(feature_stats)\n",
    "\n",
    "print(\"\\nFeature standard deviations by class:\")\n",
    "feature_stds = features_df.groupby('label')[numeric_cols].std()\n",
    "print(feature_stds)\n",
    "\n",
    "# Calculate coefficient of variation (std/mean) to find stable features\n",
    "print(\"\\nCoefficient of Variation (lower is more stable):\")\n",
    "cv_by_class = feature_stds / (feature_stats.abs() + 1e-10)\n",
    "print(cv_by_class)\n",
    "\n",
    "# ============================================================================\n",
    "# FEATURE SELECTION - ROBUST FEATURES ONLY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SELECTING ROBUST FEATURES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Strategy: Use features with:\n",
    "# 1. Lower coefficient of variation (more stable)\n",
    "# 2. Good class separation\n",
    "# 3. No extreme outliers\n",
    "\n",
    "# OPTION 1: Stable features (try this first)\n",
    "selected_features = [\"flux_std\", \"flux_mean\", \"time_span\"]\n",
    "\n",
    "# OPTION 2: If flux features still have issues, try these:\n",
    "# selected_features = [\"n_points\", \"time_span\", \"flux_mean\"]\n",
    "\n",
    "# OPTION 3: Try delta features:\n",
    "# selected_features = [\"delta_flux\", \"flux_mean\", \"time_span\"]\n",
    "\n",
    "print(f\"\\nSelected features: {selected_features}\")\n",
    "\n",
    "# Verify features exist\n",
    "for f in selected_features:\n",
    "    if f not in features_df.columns:\n",
    "        raise ValueError(f\"Feature '{f}' not found! Available: {features_df.columns.tolist()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. PREPARE DATA WITH OUTLIER HANDLING\n",
    "# ============================================================================\n",
    "\n",
    "X_raw = features_df[selected_features].values\n",
    "y_str = features_df[\"label\"].values\n",
    "\n",
    "# Map labels\n",
    "label_mapping = {\"SNII\": 0, \"SNIa\": 1}\n",
    "y = np.array([label_mapping[val] for val in y_str])\n",
    "\n",
    "print(f\"\\nRaw data shape: {X_raw.shape}\")\n",
    "print(f\"Class distribution: {dict(zip(*np.unique(y, return_counts=True)))}\")\n",
    "\n",
    "# Check for NaN/inf\n",
    "if np.any(np.isnan(X_raw)) or np.any(np.isinf(X_raw)):\n",
    "    print(\"\\nWARNING: NaN or Inf values detected!\")\n",
    "    X_raw = np.nan_to_num(X_raw, nan=0.0, posinf=1e10, neginf=-1e10)\n",
    "\n",
    "# Analyze feature distributions BEFORE scaling\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RAW FEATURE STATISTICS (BEFORE SCALING)\")\n",
    "print(\"=\" * 70)\n",
    "for i, feat in enumerate(selected_features):\n",
    "    feat_data = X_raw[:, i]\n",
    "    print(f\"\\n{feat}:\")\n",
    "    print(f\"  Min:    {feat_data.min():.4f}\")\n",
    "    print(f\"  Max:    {feat_data.max():.4f}\")\n",
    "    print(f\"  Mean:   {feat_data.mean():.4f}\")\n",
    "    print(f\"  Median: {np.median(feat_data):.4f}\")\n",
    "    print(f\"  Std:    {feat_data.std():.4f}\")\n",
    "    print(f\"  25%:    {np.percentile(feat_data, 25):.4f}\")\n",
    "    print(f\"  75%:    {np.percentile(feat_data, 75):.4f}\")\n",
    "    print(f\"  99%:    {np.percentile(feat_data, 99):.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# KEY FIX: OUTLIER-ROBUST SCALING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"APPLYING OUTLIER-ROBUST SCALING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Method 1: Clip outliers at 99th percentile\n",
    "X_clipped = X_raw.copy()\n",
    "for i in range(X_clipped.shape[1]):\n",
    "    p99 = np.percentile(X_clipped[:, i], 99)\n",
    "    p1 = np.percentile(X_clipped[:, i], 1)\n",
    "    X_clipped[:, i] = np.clip(X_clipped[:, i], p1, p99)\n",
    "    print(f\"Feature {i} ({selected_features[i]}) clipped to [{p1:.4f}, {p99:.4f}]\")\n",
    "\n",
    "# Method 2: Apply log transform to reduce dynamic range (optional)\n",
    "# Use this if features are still heavily skewed\n",
    "X_processed = X_clipped.copy()\n",
    "\n",
    "# Check if any features have large dynamic range (max/min > 1000)\n",
    "for i in range(X_processed.shape[1]):\n",
    "    feat_min = X_processed[:, i].min()\n",
    "    feat_max = X_processed[:, i].max()\n",
    "    dynamic_range = (feat_max - feat_min) / (abs(feat_min) + 1e-10)\n",
    "    \n",
    "    if dynamic_range > 100:\n",
    "        print(f\"  Feature {i} has large dynamic range ({dynamic_range:.1f}), applying log transform\")\n",
    "        # Shift to positive + log transform\n",
    "        X_processed[:, i] = np.log1p(X_processed[:, i] - X_processed[:, i].min() + 1)\n",
    "\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# 4. TRAIN-TEST SPLIT\n",
    "# ============================================================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "print(f\"Train class distribution: {dict(zip(*np.unique(y_train, return_counts=True)))}\")\n",
    "print(f\"Test class distribution: {dict(zip(*np.unique(y_test, return_counts=True)))}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# 5. SCALE TO QUANTUM ANGLES [0, œÄ]\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SCALING TO QUANTUM ANGLES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Use MinMaxScaler AFTER outlier removal\n",
    "scaler = MinMaxScaler(feature_range=(0, np.pi))\n",
    "X_train_angles = scaler.fit_transform(X_train)\n",
    "X_test_angles = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\nScaled feature ranges (train):\")\n",
    "print(f\"  Min:    {X_train_angles.min(axis=0)}\")\n",
    "print(f\"  Max:    {X_train_angles.max(axis=0)}\")\n",
    "print(f\"  Mean:   {X_train_angles.mean(axis=0)}\")\n",
    "print(f\"  Median: {np.median(X_train_angles, axis=0)}\")\n",
    "\n",
    "# CRITICAL CHECK: Are features well-distributed?\n",
    "print(\"\\nFeature distribution check:\")\n",
    "for i, feat in enumerate(selected_features):\n",
    "    mean_val = X_train_angles[:, i].mean()\n",
    "    median_val = np.median(X_train_angles[:, i])\n",
    "    print(f\"  {feat}: mean={mean_val:.3f}, median={median_val:.3f}\")\n",
    "    \n",
    "    if mean_val < 0.3 or mean_val > 2.8:\n",
    "        print(f\"    ‚ö†Ô∏è  WARNING: Feature concentrated near boundary!\")\n",
    "    elif abs(mean_val - np.pi/2) < 0.5:\n",
    "        print(f\"    ‚úì Good: Feature centered around œÄ/2\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# 6. BUILD QUANTUM CIRCUIT\n",
    "# ============================================================================\n",
    "\n",
    "num_features = X_train_angles.shape[1]\n",
    "num_qubits = num_features\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"BUILDING {num_qubits}-QUBIT QUANTUM CIRCUIT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Feature map with strong entanglement\n",
    "feature_map = ZZFeatureMap(\n",
    "    feature_dimension=num_features,\n",
    "    reps=2,\n",
    "    entanglement=\"full\"\n",
    ")\n",
    "\n",
    "# Deeper ansatz for better expressivity\n",
    "ansatz = TwoLocal(\n",
    "    num_qubits=num_qubits,\n",
    "    reps=3,\n",
    "    rotation_blocks=[\"ry\", \"rz\"],\n",
    "    entanglement_blocks=\"cz\",\n",
    "    entanglement=\"full\"\n",
    ")\n",
    "\n",
    "# Combine\n",
    "from qiskit import QuantumCircuit\n",
    "\n",
    "circuit = QuantumCircuit(num_qubits)\n",
    "circuit.compose(feature_map, inplace=True)\n",
    "circuit.compose(ansatz, inplace=True)\n",
    "\n",
    "print(f\"\\nCircuit statistics:\")\n",
    "print(f\"  Depth: {circuit.depth()}\")\n",
    "print(f\"  Total parameters: {circuit.num_parameters}\")\n",
    "print(f\"  Input params: {len(list(feature_map.parameters))}\")\n",
    "print(f\"  Trainable params: {len(list(ansatz.parameters))}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# 7. CREATE QUANTUM NEURAL NETWORK\n",
    "# ============================================================================\n",
    "\n",
    "estimator = Estimator()\n",
    "\n",
    "input_params = list(feature_map.parameters)\n",
    "weight_params = list(ansatz.parameters)\n",
    "\n",
    "qnn = EstimatorQNN(\n",
    "    estimator=estimator,\n",
    "    circuit=circuit,\n",
    "    input_params=input_params,\n",
    "    weight_params=weight_params,\n",
    ")\n",
    "\n",
    "print(\"EstimatorQNN created\")\n",
    "print(f\"  Input dimension: {len(input_params)}\")\n",
    "print(f\"  Trainable weights: {len(weight_params)}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# 8. CREATE QUANTUM CLASSIFIER WITH MORE ITERATIONS\n",
    "# ============================================================================\n",
    "\n",
    "# Try higher iterations since we fixed the scaling\n",
    "optimizer = COBYLA(maxiter=300)  # Increased to 300\n",
    "\n",
    "q_clf = NeuralNetworkClassifier(\n",
    "    neural_network=qnn,\n",
    "    optimizer=optimizer,\n",
    "    one_hot=False,\n",
    ")\n",
    "\n",
    "print(f\"Quantum classifier: COBYLA(maxiter=300)\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# 9. TRAIN QUANTUM MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAINING QUANTUM MODEL (this may take 5-7 minutes)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "q_clf.fit(X_train_angles, y_train)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"\\n‚úì Training completed in {training_time:.1f}s ({training_time/60:.1f} min)\")\n",
    "\n",
    "# ============================================================================\n",
    "# 10. EVALUATE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EVALUATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Predictions\n",
    "y_pred_raw = q_clf.predict(X_test_angles)\n",
    "print(f\"\\nRaw predictions: {np.unique(y_pred_raw)}\")\n",
    "\n",
    "y_pred_q = np.where(y_pred_raw <= 0, 0, 1)\n",
    "print(f\"Binary predictions: {np.unique(y_pred_q)}\")\n",
    "print(f\"Prediction counts: {dict(zip(*np.unique(y_pred_q, return_counts=True)))}\")\n",
    "\n",
    "# Probability scores\n",
    "y_proba_q = q_clf.predict_proba(X_test_angles)\n",
    "scores = y_proba_q.ravel()\n",
    "print(f\"Score range: [{scores.min():.4f}, {scores.max():.4f}]\")\n",
    "print(f\"Score mean: {scores.mean():.4f}, std: {scores.std():.4f}\\n\")\n",
    "\n",
    "# Metrics\n",
    "q_acc = accuracy_score(y_test, y_pred_q)\n",
    "q_auc = roc_auc_score(y_test, scores)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nüéØ Accuracy: {q_acc:.1%} ({q_acc:.3f})\")\n",
    "print(f\"üìä AUC:      {q_auc:.1%} ({q_auc:.3f})\")\n",
    "\n",
    "# Comparison\n",
    "random_acc = 0.5\n",
    "print(f\"\\nüìà Random baseline: {random_acc:.1%}\")\n",
    "print(f\"üìà Improvement: {(q_acc - random_acc):.1%} ({q_acc - random_acc:+.3f})\")\n",
    "\n",
    "classical_acc = 0.75  # From your classical work\n",
    "print(f\"\\nüìä Classical baseline: {classical_acc:.1%}\")\n",
    "print(f\"üìä Gap to classical: {(q_acc - classical_acc):.1%} ({q_acc - classical_acc:+.3f})\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\" * 70)\n",
    "print(classification_report(\n",
    "    y_test, y_pred_q,\n",
    "    labels=[0, 1],\n",
    "    target_names=[\"SNII (0)\", \"SNIa (1)\"],\n",
    "    zero_division=0,\n",
    "))\n",
    "\n",
    "# Confusion matrix\n",
    "cm_q = confusion_matrix(y_test, y_pred_q, labels=[0, 1])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(\"                Predicted\")\n",
    "print(\"              SNII  SNIa\")\n",
    "print(f\"Actual SNII   {cm_q[0,0]:3d}   {cm_q[0,1]:3d}\")\n",
    "print(f\"       SNIa   {cm_q[1,0]:3d}   {cm_q[1,1]:3d}\\n\")\n",
    "\n",
    "# Calculate balanced metrics\n",
    "tn, fp, fn, tp = cm_q.ravel()\n",
    "sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "balanced_acc = (sensitivity + specificity) / 2\n",
    "\n",
    "print(f\"Sensitivity (recall for SNIa): {sensitivity:.1%}\")\n",
    "print(f\"Specificity (recall for SNII): {specificity:.1%}\")\n",
    "print(f\"Balanced accuracy: {balanced_acc:.1%}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# 11. SAVE RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "results = {\n",
    "    \"model\": \"EstimatorQNN\",\n",
    "    \"version\": \"outlier_robust\",\n",
    "    \"features\": selected_features,\n",
    "    \"preprocessing\": {\n",
    "        \"outlier_clipping\": \"99th percentile\",\n",
    "        \"scaling\": \"MinMaxScaler [0, œÄ]\",\n",
    "        \"log_transform\": \"conditional on dynamic range\"\n",
    "    },\n",
    "    \"num_qubits\": num_qubits,\n",
    "    \"circuit_depth\": int(circuit.depth()),\n",
    "    \"num_parameters\": int(circuit.num_parameters),\n",
    "    \"trainable_params\": len(weight_params),\n",
    "    \"training_time_seconds\": float(training_time),\n",
    "    \"optimizer\": \"COBYLA\",\n",
    "    \"max_iterations\": 300,\n",
    "    \"feature_map\": {\n",
    "        \"type\": \"ZZFeatureMap\",\n",
    "        \"reps\": 2,\n",
    "        \"entanglement\": \"full\"\n",
    "    },\n",
    "    \"ansatz\": {\n",
    "        \"type\": \"TwoLocal\",\n",
    "        \"reps\": 3,\n",
    "        \"rotation_blocks\": [\"ry\", \"rz\"],\n",
    "        \"entanglement_blocks\": \"cz\",\n",
    "        \"entanglement\": \"full\"\n",
    "    },\n",
    "    \"results\": {\n",
    "        \"test_samples\": int(len(y_test)),\n",
    "        \"accuracy\": float(q_acc),\n",
    "        \"auc\": float(q_auc),\n",
    "        \"balanced_accuracy\": float(balanced_acc),\n",
    "        \"sensitivity\": float(sensitivity),\n",
    "        \"specificity\": float(specificity),\n",
    "        \"confusion_matrix\": cm_q.tolist(),\n",
    "        \"random_baseline\": 0.5,\n",
    "        \"classical_baseline\": 0.75,\n",
    "    }\n",
    "}\n",
    "\n",
    "results_path = os.path.join(RESULTS_DIR, \"plasticc_quantum_results_robust.json\")\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to: {results_path}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 12. FINAL ASSESSMENT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FINAL ASSESSMENT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if q_acc < 0.52:\n",
    "    print(\"\\n‚ö†Ô∏è  Model performed at random level (<52%)\")\n",
    "    print(\"\\nPossible issues:\")\n",
    "    print(\"  1. Features still have poor separation\")\n",
    "    print(\"  2. Circuit might need different architecture\")\n",
    "    print(\"  3. Dataset too small for quantum advantage\")\n",
    "    print(\"  4. Try different feature combinations\")\n",
    "    \n",
    "elif q_acc < 0.60:\n",
    "    print(\"\\n‚úì Model learned something (52-60%)\")\n",
    "    print(\"\\nThis is acceptable for quantum on small dataset.\")\n",
    "    print(\"Gap to classical (75%) expected due to:\")\n",
    "    print(\"  - Only 3 features vs 16 in classical\")\n",
    "    print(\"  - Small training set (480 samples)\")\n",
    "    print(\"  - NISQ hardware limitations\")\n",
    "    \n",
    "elif q_acc < 0.70:\n",
    "    print(\"\\n‚úÖ Good quantum performance! (60-70%)\")\n",
    "    print(\"\\nThis is strong result for quantum ML on small dataset.\")\n",
    "    print(\"Demonstrates quantum circuits can learn meaningful patterns.\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nüéâ Excellent quantum performance! (>70%)\")\n",
    "    print(\"\\nQuantum approaching classical performance!\")\n",
    "    print(\"This is impressive for only 3 features.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"  1. Document results in README\")\n",
    "print(\"  2. Compare quantum vs classical approaches\")\n",
    "print(\"  3. Discuss learnings about quantum ML limitations\")\n",
    "print(\"  4. Consider trying different feature sets if time permits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "625efbd1-8144-4a5a-9c80-ede528dd685d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "QUANTUM ML - FINAL VERSION (1072 SAMPLES)\n",
      "======================================================================\n",
      "\n",
      "Features path: ../data/plasticc/transient_features.csv\n",
      "Results dir: ../results\n",
      "\n",
      "Loaded 1072 samples\n",
      "Class distribution:\n",
      "label\n",
      "SNII    549\n",
      "SNIa    523\n",
      "Name: count, dtype: int64\n",
      "\n",
      "======================================================================\n",
      "AUTO-SELECTING TOP 3 FEATURES BY CORRELATION\n",
      "======================================================================\n",
      "\n",
      "Top 10 features:\n",
      "           feature  correlation  correlation_signed      p_value\n",
      "         time_span     0.280059           -0.280059 9.061588e-21\n",
      "      decline_time     0.268915           -0.268915 3.248802e-19\n",
      "           mag_max     0.150529            0.150529 7.382729e-07\n",
      "           mag_std     0.142485            0.142485 2.818433e-06\n",
      "          mag_mean     0.133558            0.133558 1.146827e-05\n",
      "         mag_range     0.104832            0.104832 5.864396e-04\n",
      "         rise_time     0.096462           -0.096462 1.567008e-03\n",
      "mean_decline_slope     0.063565            0.063565 3.744478e-02\n",
      "         flux_mean     0.041182           -0.041182 1.778611e-01\n",
      "           mag_min     0.033363            0.033363 2.750981e-01\n",
      "\n",
      "======================================================================\n",
      "üéØ SELECTED FOR QUANTUM: ['time_span', 'decline_time', 'mag_max']\n",
      "======================================================================\n",
      "\n",
      "Class separation analysis:\n",
      "\n",
      "time_span:\n",
      "  SNIa: Œº=71.786, œÉ=43.356\n",
      "  SNII: Œº=114.155, œÉ=92.194\n",
      "  Separation: 42.369 (0.46œÉ)\n",
      "\n",
      "decline_time:\n",
      "  SNIa: Œº=58.290, œÉ=43.995\n",
      "  SNII: Œº=98.044, œÉ=89.706\n",
      "  Separation: 39.754 (0.44œÉ)\n",
      "\n",
      "mag_max:\n",
      "  SNIa: Œº=-3.060, œÉ=1.078\n",
      "  SNII: Œº=-3.386, œÉ=1.063\n",
      "  Separation: 0.326 (0.31œÉ)\n",
      "\n",
      "======================================================================\n",
      "DATA PREPARATION\n",
      "======================================================================\n",
      "\n",
      "Selected features shape: (1072, 3)\n",
      "Labels shape: (1072,)\n",
      "\n",
      "======================================================================\n",
      "OUTLIER-ROBUST PREPROCESSING\n",
      "======================================================================\n",
      "Feature 0 (time_span): clipped to [16.8480, 398.5351]\n",
      "Feature 1 (decline_time): clipped to [3.0397, 384.1666]\n",
      "Feature 2 (mag_max): clipped to [-5.9066, -1.0485]\n",
      "  Feature 1: high dynamic range (125.4), applying log transform\n",
      "\n",
      "======================================================================\n",
      "TRAIN-TEST SPLIT\n",
      "======================================================================\n",
      "Train: (857, 3), Test: (215, 3)\n",
      "Train distribution: {np.int64(0): np.int64(439), np.int64(1): np.int64(418)}\n",
      "Test distribution: {np.int64(0): np.int64(110), np.int64(1): np.int64(105)}\n",
      "\n",
      "======================================================================\n",
      "SCALING TO QUANTUM ANGLES\n",
      "======================================================================\n",
      "\n",
      "Angle ranges (train):\n",
      "  Min:    [0. 0. 0.]\n",
      "  Max:    [3.14159265 3.14159265 3.14159265]\n",
      "  Mean:   [0.62131005 1.94577922 1.73820283]\n",
      "  Median: [0.47747707 1.98878424 1.72269831]\n",
      "\n",
      "Distribution quality check:\n",
      "  time_span: mean=0.621, median=0.477\n",
      "  decline_time: mean=1.946, median=1.989 ‚úì Well-centered\n",
      "  mag_max: mean=1.738, median=1.723 ‚úì Well-centered\n",
      "\n",
      "======================================================================\n",
      "BUILDING 3-QUBIT QUANTUM CIRCUIT\n",
      "======================================================================\n",
      "\n",
      "Circuit statistics:\n",
      "  Depth: 2\n",
      "  Parameters: 27\n",
      "  Input params: 3\n",
      "  Trainable params: 24\n",
      "\n",
      "EstimatorQNN created:\n",
      "  Input dimension: 3\n",
      "  Trainable weights: 24\n",
      "\n",
      "Quantum classifier: COBYLA(maxiter=300)\n",
      "\n",
      "======================================================================\n",
      "TRAINING QUANTUM MODEL\n",
      "======================================================================\n",
      "This will take 5-10 minutes...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4j/986s_f794zq87n31mh_7ls200000gn/T/ipykernel_80587/2605216957.py:252: DeprecationWarning: The class ``qiskit.primitives.estimator.Estimator`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseEstimatorV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `Estimator` class is `StatevectorEstimator`.\n",
      "  estimator = Estimator()\n",
      "/var/folders/4j/986s_f794zq87n31mh_7ls200000gn/T/ipykernel_80587/2605216957.py:257: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
      "  qnn = EstimatorQNN(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Training completed in 600.6s (10.0 min)\n",
      "\n",
      "======================================================================\n",
      "EVALUATION\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "QUANTUM RESULTS\n",
      "======================================================================\n",
      "\n",
      "üéØ Accuracy: 52.1% (0.521)\n",
      "üìä AUC:      58.7% (0.587)\n",
      "\n",
      "üìà Random baseline:    50.0%\n",
      "üìà Quantum vs random:  2.1% (+0.021)\n",
      "\n",
      "üìä Classical (Ensemble): 74.4%\n",
      "üìä Gap to classical:     -22.3% (-0.223)\n",
      "\n",
      "======================================================================\n",
      "CLASSIFICATION REPORT\n",
      "======================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        SNII       0.59      0.20      0.30       110\n",
      "        SNIa       0.51      0.86      0.64       105\n",
      "\n",
      "    accuracy                           0.52       215\n",
      "   macro avg       0.55      0.53      0.47       215\n",
      "weighted avg       0.55      0.52      0.46       215\n",
      "\n",
      "Confusion Matrix:\n",
      "              SNII  SNIa\n",
      "Actual SNII    22    88\n",
      "       SNIa    15    90\n",
      "\n",
      "Sensitivity (SNIa recall): 85.7%\n",
      "Specificity (SNII recall): 20.0%\n",
      "Balanced accuracy:         52.9%\n",
      "\n",
      "‚úì Results saved: ../results/plasticc_quantum_results_final.json\n",
      "\n",
      "======================================================================\n",
      "FINAL ASSESSMENT\n",
      "======================================================================\n",
      "\n",
      "‚úì Minimal learning: 52.1% accuracy\n",
      "Model learned something, but gap to classical remains large\n",
      "\n",
      "======================================================================\n",
      "PROJECT COMPLETE!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 03_quantum_classifier.ipynb - FINAL VERSION WITH AUTO FEATURE SELECTION\n",
    "# Quantum ML for PLAsTiCC Transient Classification\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    roc_auc_score\n",
    ")\n",
    "from scipy.stats import pointbiserialr\n",
    "\n",
    "# Quantum imports\n",
    "from qiskit.circuit.library import ZZFeatureMap, TwoLocal\n",
    "from qiskit.primitives import Estimator\n",
    "from qiskit_algorithms.optimizers import COBYLA\n",
    "\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
    "\n",
    "# ============================================================================\n",
    "# 1. SETUP\n",
    "# ============================================================================\n",
    "\n",
    "DATA_DIR = os.path.join(\"..\", \"data\", \"plasticc\")\n",
    "FEATURES_PATH = os.path.join(DATA_DIR, \"transient_features.csv\")\n",
    "\n",
    "RESULTS_DIR = os.path.join(\"..\", \"results\")\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"QUANTUM ML - FINAL VERSION (1072 SAMPLES)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nFeatures path: {FEATURES_PATH}\")\n",
    "print(f\"Results dir: {RESULTS_DIR}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. LOAD DATA & AUTO-SELECT TOP 3 FEATURES\n",
    "# ============================================================================\n",
    "\n",
    "features_df = pd.read_csv(FEATURES_PATH)\n",
    "print(f\"Loaded {len(features_df)} samples\")\n",
    "print(f\"Class distribution:\\n{features_df['label'].value_counts()}\\n\")\n",
    "\n",
    "# All feature columns (16 features)\n",
    "feature_cols = [\n",
    "    \"mag_min\", \"mag_max\", \"mag_mean\", \"mag_std\", \"mag_range\",\n",
    "    \"flux_max\", \"flux_mean\", \"flux_std\",\n",
    "    \"time_span\", \"rise_time\", \"decline_time\", \"rise_decline_ratio\",\n",
    "    \"mean_rise_slope\", \"mean_decline_slope\", \"max_slope\",\n",
    "    \"n_points\"\n",
    "]\n",
    "\n",
    "X_full = features_df[feature_cols].values\n",
    "y_str = features_df['label'].values\n",
    "\n",
    "label_map = {'SNII': 0, 'SNIa': 1}\n",
    "y = np.array([label_map[label] for label in y_str])\n",
    "\n",
    "# ============================================================================\n",
    "# FEATURE CORRELATION - AUTO-SELECT TOP 3\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"AUTO-SELECTING TOP 3 FEATURES BY CORRELATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "correlations = []\n",
    "for i, feat in enumerate(feature_cols):\n",
    "    corr, pval = pointbiserialr(y, X_full[:, i])\n",
    "    correlations.append({\n",
    "        'feature': feat,\n",
    "        'correlation': abs(corr),\n",
    "        'correlation_signed': corr,\n",
    "        'p_value': pval\n",
    "    })\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('correlation', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 features:\")\n",
    "print(corr_df.head(10).to_string(index=False))\n",
    "\n",
    "# Select TOP 3\n",
    "selected_features = corr_df.head(3)['feature'].tolist()\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"üéØ SELECTED FOR QUANTUM: {selected_features}\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Show separation\n",
    "print(\"\\nClass separation analysis:\")\n",
    "for feat in selected_features:\n",
    "    feat_idx = feature_cols.index(feat)\n",
    "    feat_data = X_full[:, feat_idx]\n",
    "    \n",
    "    snia_vals = feat_data[y == 1]\n",
    "    snii_vals = feat_data[y == 0]\n",
    "    \n",
    "    sep = abs(snia_vals.mean() - snii_vals.mean())\n",
    "    sep_sigma = sep / snii_vals.std() if snii_vals.std() > 0 else 0\n",
    "    \n",
    "    print(f\"\\n{feat}:\")\n",
    "    print(f\"  SNIa: Œº={snia_vals.mean():.3f}, œÉ={snia_vals.std():.3f}\")\n",
    "    print(f\"  SNII: Œº={snii_vals.mean():.3f}, œÉ={snii_vals.std():.3f}\")\n",
    "    print(f\"  Separation: {sep:.3f} ({sep_sigma:.2f}œÉ)\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. PREPARE DATA WITH SELECTED FEATURES\n",
    "# ============================================================================\n",
    "\n",
    "X_selected = features_df[selected_features].values\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"DATA PREPARATION\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nSelected features shape: {X_selected.shape}\")\n",
    "print(f\"Labels shape: {y.shape}\")\n",
    "\n",
    "# Check for NaN/inf\n",
    "if np.any(np.isnan(X_selected)) or np.any(np.isinf(X_selected)):\n",
    "    print(\"‚ö†Ô∏è  WARNING: NaN/Inf detected, cleaning...\")\n",
    "    X_selected = np.nan_to_num(X_selected, nan=0.0, posinf=1e10, neginf=-1e10)\n",
    "\n",
    "# ============================================================================\n",
    "# 4. OUTLIER-ROBUST PREPROCESSING\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"OUTLIER-ROBUST PREPROCESSING\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Clip outliers at 99th percentile\n",
    "X_clipped = X_selected.copy()\n",
    "for i in range(X_clipped.shape[1]):\n",
    "    p99 = np.percentile(X_clipped[:, i], 99)\n",
    "    p1 = np.percentile(X_clipped[:, i], 1)\n",
    "    X_clipped[:, i] = np.clip(X_clipped[:, i], p1, p99)\n",
    "    print(f\"Feature {i} ({selected_features[i]}): clipped to [{p1:.4f}, {p99:.4f}]\")\n",
    "\n",
    "# Apply log transform if high dynamic range\n",
    "X_processed = X_clipped.copy()\n",
    "for i in range(X_processed.shape[1]):\n",
    "    feat_min = X_processed[:, i].min()\n",
    "    feat_max = X_processed[:, i].max()\n",
    "    dynamic_range = (feat_max - feat_min) / (abs(feat_min) + 1e-10)\n",
    "    \n",
    "    if dynamic_range > 100:\n",
    "        print(f\"  Feature {i}: high dynamic range ({dynamic_range:.1f}), applying log transform\")\n",
    "        X_processed[:, i] = np.log1p(X_processed[:, i] - X_processed[:, i].min() + 1)\n",
    "\n",
    "# ============================================================================\n",
    "# 5. TRAIN-TEST SPLIT\n",
    "# ============================================================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"TRAIN-TEST SPLIT\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "print(f\"Train distribution: {dict(zip(*np.unique(y_train, return_counts=True)))}\")\n",
    "print(f\"Test distribution: {dict(zip(*np.unique(y_test, return_counts=True)))}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 6. SCALE TO QUANTUM ANGLES [0, œÄ]\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SCALING TO QUANTUM ANGLES\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, np.pi))\n",
    "X_train_angles = scaler.fit_transform(X_train)\n",
    "X_test_angles = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nAngle ranges (train):\")\n",
    "print(f\"  Min:    {X_train_angles.min(axis=0)}\")\n",
    "print(f\"  Max:    {X_train_angles.max(axis=0)}\")\n",
    "print(f\"  Mean:   {X_train_angles.mean(axis=0)}\")\n",
    "print(f\"  Median: {np.median(X_train_angles, axis=0)}\")\n",
    "\n",
    "# Check distribution quality\n",
    "print(\"\\nDistribution quality check:\")\n",
    "for i, feat in enumerate(selected_features):\n",
    "    mean_val = X_train_angles[:, i].mean()\n",
    "    median_val = np.median(X_train_angles[:, i])\n",
    "    print(f\"  {feat}: mean={mean_val:.3f}, median={median_val:.3f}\", end=\"\")\n",
    "    \n",
    "    if mean_val < 0.3 or mean_val > 2.8:\n",
    "        print(\" ‚ö†Ô∏è  Near boundary\")\n",
    "    elif abs(mean_val - np.pi/2) < 0.5:\n",
    "        print(\" ‚úì Well-centered\")\n",
    "    else:\n",
    "        print(\"\")\n",
    "\n",
    "# ============================================================================\n",
    "# 7. BUILD QUANTUM CIRCUIT\n",
    "# ============================================================================\n",
    "\n",
    "num_qubits = X_train_angles.shape[1]\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"BUILDING {num_qubits}-QUBIT QUANTUM CIRCUIT\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Feature map\n",
    "feature_map = ZZFeatureMap(\n",
    "    feature_dimension=num_qubits,\n",
    "    reps=2,\n",
    "    entanglement=\"full\"\n",
    ")\n",
    "\n",
    "# Ansatz\n",
    "ansatz = TwoLocal(\n",
    "    num_qubits=num_qubits,\n",
    "    reps=3,\n",
    "    rotation_blocks=[\"ry\", \"rz\"],\n",
    "    entanglement_blocks=\"cz\",\n",
    "    entanglement=\"full\"\n",
    ")\n",
    "\n",
    "# Combined circuit\n",
    "from qiskit import QuantumCircuit\n",
    "\n",
    "circuit = QuantumCircuit(num_qubits)\n",
    "circuit.compose(feature_map, inplace=True)\n",
    "circuit.compose(ansatz, inplace=True)\n",
    "\n",
    "print(f\"\\nCircuit statistics:\")\n",
    "print(f\"  Depth: {circuit.depth()}\")\n",
    "print(f\"  Parameters: {circuit.num_parameters}\")\n",
    "print(f\"  Input params: {len(list(feature_map.parameters))}\")\n",
    "print(f\"  Trainable params: {len(list(ansatz.parameters))}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 8. CREATE QNN\n",
    "# ============================================================================\n",
    "\n",
    "estimator = Estimator()\n",
    "\n",
    "input_params = list(feature_map.parameters)\n",
    "weight_params = list(ansatz.parameters)\n",
    "\n",
    "qnn = EstimatorQNN(\n",
    "    estimator=estimator,\n",
    "    circuit=circuit,\n",
    "    input_params=input_params,\n",
    "    weight_params=weight_params,\n",
    ")\n",
    "\n",
    "print(f\"\\nEstimatorQNN created:\")\n",
    "print(f\"  Input dimension: {len(input_params)}\")\n",
    "print(f\"  Trainable weights: {len(weight_params)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 9. CREATE CLASSIFIER\n",
    "# ============================================================================\n",
    "\n",
    "optimizer = COBYLA(maxiter=300)\n",
    "\n",
    "q_clf = NeuralNetworkClassifier(\n",
    "    neural_network=qnn,\n",
    "    optimizer=optimizer,\n",
    "    one_hot=False,\n",
    ")\n",
    "\n",
    "print(f\"\\nQuantum classifier: COBYLA(maxiter=300)\")\n",
    "\n",
    "# ============================================================================\n",
    "# 10. TRAIN\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"TRAINING QUANTUM MODEL\")\n",
    "print(f\"{'='*70}\")\n",
    "print(\"This will take 5-10 minutes...\\n\")\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "q_clf.fit(X_train_angles, y_train)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"\\n‚úì Training completed in {training_time:.1f}s ({training_time/60:.1f} min)\")\n",
    "\n",
    "# ============================================================================\n",
    "# 11. EVALUATE\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"EVALUATION\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Predictions\n",
    "y_pred_raw = q_clf.predict(X_test_angles)\n",
    "y_pred_q = np.where(y_pred_raw <= 0, 0, 1)\n",
    "\n",
    "# Probability scores\n",
    "y_proba_q = q_clf.predict_proba(X_test_angles)\n",
    "scores = y_proba_q.ravel()\n",
    "\n",
    "# Metrics\n",
    "q_acc = accuracy_score(y_test, y_pred_q)\n",
    "q_auc = roc_auc_score(y_test, scores)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"QUANTUM RESULTS\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nüéØ Accuracy: {q_acc:.1%} ({q_acc:.3f})\")\n",
    "print(f\"üìä AUC:      {q_auc:.1%} ({q_auc:.3f})\")\n",
    "\n",
    "# Comparison\n",
    "print(f\"\\nüìà Random baseline:    50.0%\")\n",
    "print(f\"üìà Quantum vs random:  {(q_acc - 0.5):.1%} ({q_acc - 0.5:+.3f})\")\n",
    "print(f\"\\nüìä Classical (Ensemble): 74.4%\")\n",
    "print(f\"üìä Gap to classical:     {(q_acc - 0.744):.1%} ({q_acc - 0.744:+.3f})\")\n",
    "\n",
    "# Classification report\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(f\"{'='*70}\")\n",
    "print(classification_report(\n",
    "    y_test, y_pred_q,\n",
    "    labels=[0, 1],\n",
    "    target_names=[\"SNII\", \"SNIa\"],\n",
    "    zero_division=0,\n",
    "))\n",
    "\n",
    "# Confusion matrix\n",
    "cm_q = confusion_matrix(y_test, y_pred_q, labels=[0, 1])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(\"              SNII  SNIa\")\n",
    "print(f\"Actual SNII   {cm_q[0,0]:3d}   {cm_q[0,1]:3d}\")\n",
    "print(f\"       SNIa   {cm_q[1,0]:3d}   {cm_q[1,1]:3d}\")\n",
    "\n",
    "# Balanced metrics\n",
    "tn, fp, fn, tp = cm_q.ravel()\n",
    "sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "balanced_acc = (sensitivity + specificity) / 2\n",
    "\n",
    "print(f\"\\nSensitivity (SNIa recall): {sensitivity:.1%}\")\n",
    "print(f\"Specificity (SNII recall): {specificity:.1%}\")\n",
    "print(f\"Balanced accuracy:         {balanced_acc:.1%}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 12. SAVE RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "results = {\n",
    "    \"dataset_size\": int(len(features_df)),\n",
    "    \"train_size\": int(len(X_train)),\n",
    "    \"test_size\": int(len(X_test)),\n",
    "    \"model\": \"EstimatorQNN\",\n",
    "    \"features\": selected_features,\n",
    "    \"num_qubits\": num_qubits,\n",
    "    \"circuit_depth\": int(circuit.depth()),\n",
    "    \"trainable_params\": len(weight_params),\n",
    "    \"training_time_seconds\": float(training_time),\n",
    "    \"optimizer\": \"COBYLA\",\n",
    "    \"max_iterations\": 300,\n",
    "    \"results\": {\n",
    "        \"accuracy\": float(q_acc),\n",
    "        \"auc\": float(q_auc),\n",
    "        \"balanced_accuracy\": float(balanced_acc),\n",
    "        \"sensitivity\": float(sensitivity),\n",
    "        \"specificity\": float(specificity),\n",
    "        \"confusion_matrix\": cm_q.tolist(),\n",
    "    },\n",
    "    \"baselines\": {\n",
    "        \"random\": 0.5,\n",
    "        \"classical_ensemble\": 0.744,\n",
    "        \"classical_random_forest\": 0.758,\n",
    "    }\n",
    "}\n",
    "\n",
    "results_path = os.path.join(RESULTS_DIR, \"plasticc_quantum_results_final.json\")\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úì Results saved: {results_path}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 13. FINAL ASSESSMENT\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"FINAL ASSESSMENT\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "if q_acc < 0.52:\n",
    "    status = \"‚ö†Ô∏è  Random level\"\n",
    "    msg = \"Model did not learn meaningful patterns\"\n",
    "elif q_acc < 0.60:\n",
    "    status = \"‚úì Minimal learning\"\n",
    "    msg = \"Model learned something, but gap to classical remains large\"\n",
    "elif q_acc < 0.70:\n",
    "    status = \"‚úÖ Good performance\"\n",
    "    msg = \"Strong quantum learning! Approaching classical performance\"\n",
    "else:\n",
    "    status = \"üéâ Excellent!\"\n",
    "    msg = \"Quantum rivaling classical performance!\"\n",
    "\n",
    "print(f\"\\n{status}: {q_acc:.1%} accuracy\")\n",
    "print(f\"{msg}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"PROJECT COMPLETE!\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad6d5cb-5539-4442-9470-8a8d253784bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
