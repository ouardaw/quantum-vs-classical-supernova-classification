{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e0b24b2-90a4-4815-82e7-2944857beeb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transient_id</th>\n",
       "      <th>n_points</th>\n",
       "      <th>mag_min</th>\n",
       "      <th>mag_max</th>\n",
       "      <th>mag_mean</th>\n",
       "      <th>mag_std</th>\n",
       "      <th>mag_range</th>\n",
       "      <th>flux_max</th>\n",
       "      <th>flux_mean</th>\n",
       "      <th>flux_std</th>\n",
       "      <th>time_span</th>\n",
       "      <th>rise_time</th>\n",
       "      <th>decline_time</th>\n",
       "      <th>rise_decline_ratio</th>\n",
       "      <th>mean_rise_slope</th>\n",
       "      <th>mean_decline_slope</th>\n",
       "      <th>max_slope</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>215282</td>\n",
       "      <td>21</td>\n",
       "      <td>-3.539098</td>\n",
       "      <td>-1.349829</td>\n",
       "      <td>-2.679177</td>\n",
       "      <td>0.594565</td>\n",
       "      <td>2.189269</td>\n",
       "      <td>26.039886</td>\n",
       "      <td>13.479886</td>\n",
       "      <td>6.350749</td>\n",
       "      <td>113.5933</td>\n",
       "      <td>1.9995</td>\n",
       "      <td>111.5938</td>\n",
       "      <td>0.017918</td>\n",
       "      <td>-12.304446</td>\n",
       "      <td>-3.625747</td>\n",
       "      <td>178.404545</td>\n",
       "      <td>SNIa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92999561</td>\n",
       "      <td>5</td>\n",
       "      <td>-5.858902</td>\n",
       "      <td>-3.968508</td>\n",
       "      <td>-5.185998</td>\n",
       "      <td>0.688865</td>\n",
       "      <td>1.890394</td>\n",
       "      <td>220.577240</td>\n",
       "      <td>140.131747</td>\n",
       "      <td>67.895501</td>\n",
       "      <td>59.0308</td>\n",
       "      <td>8.0055</td>\n",
       "      <td>51.0253</td>\n",
       "      <td>0.156893</td>\n",
       "      <td>-0.165610</td>\n",
       "      <td>0.101884</td>\n",
       "      <td>0.259740</td>\n",
       "      <td>SNIa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19866</td>\n",
       "      <td>85</td>\n",
       "      <td>-6.080060</td>\n",
       "      <td>-1.458976</td>\n",
       "      <td>-4.326849</td>\n",
       "      <td>1.078168</td>\n",
       "      <td>4.621084</td>\n",
       "      <td>270.410736</td>\n",
       "      <td>82.137994</td>\n",
       "      <td>70.261176</td>\n",
       "      <td>104.7842</td>\n",
       "      <td>16.7870</td>\n",
       "      <td>87.9972</td>\n",
       "      <td>0.190767</td>\n",
       "      <td>5.602911</td>\n",
       "      <td>-4.896040</td>\n",
       "      <td>260.035027</td>\n",
       "      <td>SNIa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34971934</td>\n",
       "      <td>5</td>\n",
       "      <td>-5.973134</td>\n",
       "      <td>-5.222988</td>\n",
       "      <td>-5.640410</td>\n",
       "      <td>0.278760</td>\n",
       "      <td>0.750146</td>\n",
       "      <td>245.049469</td>\n",
       "      <td>186.256429</td>\n",
       "      <td>46.025077</td>\n",
       "      <td>17.0175</td>\n",
       "      <td>8.0140</td>\n",
       "      <td>9.0035</td>\n",
       "      <td>0.890098</td>\n",
       "      <td>-0.079878</td>\n",
       "      <td>0.085137</td>\n",
       "      <td>0.146091</td>\n",
       "      <td>SNIa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106057072</td>\n",
       "      <td>6</td>\n",
       "      <td>-5.404697</td>\n",
       "      <td>-4.004794</td>\n",
       "      <td>-4.790354</td>\n",
       "      <td>0.498553</td>\n",
       "      <td>1.399903</td>\n",
       "      <td>145.170700</td>\n",
       "      <td>91.019598</td>\n",
       "      <td>38.254045</td>\n",
       "      <td>40.0000</td>\n",
       "      <td>23.0221</td>\n",
       "      <td>16.9779</td>\n",
       "      <td>1.356004</td>\n",
       "      <td>-0.180200</td>\n",
       "      <td>0.054138</td>\n",
       "      <td>0.311822</td>\n",
       "      <td>SNIa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transient_id  n_points   mag_min   mag_max  mag_mean   mag_std  mag_range  \\\n",
       "0        215282        21 -3.539098 -1.349829 -2.679177  0.594565   2.189269   \n",
       "1      92999561         5 -5.858902 -3.968508 -5.185998  0.688865   1.890394   \n",
       "2         19866        85 -6.080060 -1.458976 -4.326849  1.078168   4.621084   \n",
       "3      34971934         5 -5.973134 -5.222988 -5.640410  0.278760   0.750146   \n",
       "4     106057072         6 -5.404697 -4.004794 -4.790354  0.498553   1.399903   \n",
       "\n",
       "     flux_max   flux_mean   flux_std  time_span  rise_time  decline_time  \\\n",
       "0   26.039886   13.479886   6.350749   113.5933     1.9995      111.5938   \n",
       "1  220.577240  140.131747  67.895501    59.0308     8.0055       51.0253   \n",
       "2  270.410736   82.137994  70.261176   104.7842    16.7870       87.9972   \n",
       "3  245.049469  186.256429  46.025077    17.0175     8.0140        9.0035   \n",
       "4  145.170700   91.019598  38.254045    40.0000    23.0221       16.9779   \n",
       "\n",
       "   rise_decline_ratio  mean_rise_slope  mean_decline_slope   max_slope label  \n",
       "0            0.017918       -12.304446           -3.625747  178.404545  SNIa  \n",
       "1            0.156893        -0.165610            0.101884    0.259740  SNIa  \n",
       "2            0.190767         5.602911           -4.896040  260.035027  SNIa  \n",
       "3            0.890098        -0.079878            0.085137    0.146091  SNIa  \n",
       "4            1.356004        -0.180200            0.054138    0.311822  SNIa  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# We drop XGBoost and LightGBM for now to avoid libomp issues on macOS\n",
    "# from xgboost import XGBClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = os.path.join(\"..\", \"data\", \"plasticc\")\n",
    "FEATURES_PATH = os.path.join(DATA_DIR, \"transient_features.csv\")\n",
    "\n",
    "RESULTS_DIR = os.path.join(\"..\", \"results\")\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "FEATURES_PATH, RESULTS_DIR\n",
    "df = pd.read_csv(FEATURES_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "087b3af2-fae9-429c-b167-882ef4cb1def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (339, 18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "SNII    181\n",
       "SNIa    158\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = pd.read_csv(FEATURES_PATH)\n",
    "\n",
    "print(\"Shape:\", features_df.shape)\n",
    "features_df.head()\n",
    "features_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1305c24c-ea6b-4882-bb52-ea128b589dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    \"n_points\",\n",
    "    \n",
    "    # Magnitude features\n",
    "    \"mag_min\", \"mag_max\", \"mag_mean\", \"mag_std\", \"mag_range\",\n",
    "    \n",
    "    # Flux features\n",
    "    \"flux_max\", \"flux_mean\", \"flux_std\",\n",
    "    \n",
    "    # Time features\n",
    "    \"time_span\", \"rise_time\", \"decline_time\", \"rise_decline_ratio\",\n",
    "    \n",
    "    # Slope features\n",
    "    \"mean_rise_slope\", \"mean_decline_slope\", \"max_slope\"\n",
    "]\n",
    "\n",
    "X = features_df[feature_cols].values\n",
    "y_str = features_df[\"label\"].values\n",
    "\n",
    "label_mapping = {\"SNIa\": 1, \"SNII\": 0}\n",
    "y = np.array([label_mapping[val] for val in y_str])\n",
    "\n",
    "X.shape, y.shape, np.unique(y, return_counts=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "001a4b39-13fe-44e0-bab5-ce86cd8ddbf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_regression', 'random_forest', 'catboost', 'ensemble']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Logistic Regression\n",
    "log_reg = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    C=2.0,\n",
    "    solver=\"lbfgs\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2. Random Forest\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=600,\n",
    "    max_depth=20,\n",
    "    min_samples_leaf=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3. CatBoost (boosting for tabular)\n",
    "cat_model = CatBoostClassifier(\n",
    "    iterations=800,\n",
    "    depth=8,\n",
    "    learning_rate=0.05,\n",
    "    loss_function=\"Logloss\",\n",
    "    verbose=False,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 4. Voting Ensemble\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"log_reg\", log_reg),\n",
    "        (\"rf\", rf),\n",
    "        (\"cat\", cat_model),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    "    weights=[1, 2, 3]\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"logistic_regression\": log_reg,\n",
    "    \"random_forest\": rf,\n",
    "    \"catboost\": cat_model,\n",
    "    \"ensemble\": ensemble,\n",
    "}\n",
    "\n",
    "list(models.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d240d636-39ba-4977-be41-aae6fa9374f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def train_and_evaluate(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Fit model and return metrics dict.\"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Some models have predict_proba, some do not\n",
    "    try:\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "    except:\n",
    "        auc = None\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    report = classification_report(\n",
    "        y_test,\n",
    "        y_pred,\n",
    "        target_names=[\"SNII (0)\", \"SNIa (1)\"],\n",
    "        output_dict=True,\n",
    "        zero_division=0,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": float(acc),\n",
    "        \"auc\": float(auc) if auc is not None else None,\n",
    "        \"confusion_matrix\": cm.tolist(),\n",
    "        \"classification_report\": report,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "547c4013-76db-4a86-bbf1-cfa618573f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training logistic_regression ===\n",
      "logistic_regression accuracy: 0.706\n",
      "logistic_regression AUC: 0.777\n",
      "\n",
      "=== Training random_forest ===\n",
      "random_forest accuracy: 0.676\n",
      "random_forest AUC: 0.819\n",
      "\n",
      "=== Training catboost ===\n",
      "catboost accuracy: 0.750\n",
      "catboost AUC: 0.843\n",
      "\n",
      "=== Training ensemble ===\n",
      "ensemble accuracy: 0.750\n",
      "ensemble AUC: 0.844\n",
      "\n",
      "=== Confusion Matrices ===\n",
      "\n",
      "logistic_regression:\n",
      "[[26 10]\n",
      " [10 22]]\n",
      "\n",
      "random_forest:\n",
      "[[22 14]\n",
      " [ 8 24]]\n",
      "\n",
      "catboost:\n",
      "[[24 12]\n",
      " [ 5 27]]\n",
      "\n",
      "ensemble:\n",
      "[[26 10]\n",
      " [ 7 25]]\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training {name} ===\")\n",
    "    \n",
    "    # These models use the scaled features\n",
    "    if name in [\"logistic_regression\", \"random_forest\", \"catboost\", \"ensemble\"]:\n",
    "        X_tr, X_te = X_train_scaled, X_test_scaled\n",
    "    else:\n",
    "        X_tr, X_te = X_train, X_test\n",
    "    \n",
    "    metrics = train_and_evaluate(model, X_tr, y_train, X_te, y_test)\n",
    "    results[name] = metrics\n",
    "    print(f\"{name} accuracy: {metrics['accuracy']:.3f}\")\n",
    "    if metrics['auc']:\n",
    "        print(f\"{name} AUC: {metrics['auc']:.3f}\")\n",
    "\n",
    "# Display confusion matrices\n",
    "print(\"\\n=== Confusion Matrices ===\")\n",
    "for name, res in results.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(np.array(res['confusion_matrix']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baa10230-1b2d-474e-b523-4ceef7a0f4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1072 samples with 18 columns\n",
      "\n",
      "Class distribution:\n",
      "label\n",
      "SNII    549\n",
      "SNIa    523\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Feature matrix: (1072, 16)\n",
      "Labels: (1072,), distribution: (array([0, 1]), array([549, 523]))\n",
      "\n",
      "Train: 857, Test: 215\n",
      "\n",
      "======================================================================\n",
      "TRAINING CLASSICAL MODELS\n",
      "======================================================================\n",
      "\n",
      "1. Logistic Regression...\n",
      "2. Random Forest...\n",
      "3. CatBoost...\n",
      "4. Ensemble (Voting)...\n",
      "\n",
      "======================================================================\n",
      "CLASSICAL MODEL RESULTS\n",
      "======================================================================\n",
      "\n",
      "Logistic Regression:\n",
      "--------------------------------------------------\n",
      "Accuracy: 71.2% (0.712)\n",
      "AUC:      77.0% (0.770)\n",
      "\n",
      "Confusion Matrix:\n",
      "              SNII  SNIa\n",
      "Actual SNII    75    35\n",
      "       SNIa    27    78\n",
      "\n",
      "Random Forest:\n",
      "--------------------------------------------------\n",
      "Accuracy: 75.8% (0.758)\n",
      "AUC:      84.5% (0.845)\n",
      "\n",
      "Confusion Matrix:\n",
      "              SNII  SNIa\n",
      "Actual SNII    81    29\n",
      "       SNIa    23    82\n",
      "\n",
      "CatBoost:\n",
      "--------------------------------------------------\n",
      "Accuracy: 74.4% (0.744)\n",
      "AUC:      84.6% (0.846)\n",
      "\n",
      "Confusion Matrix:\n",
      "              SNII  SNIa\n",
      "Actual SNII    83    27\n",
      "       SNIa    28    77\n",
      "\n",
      "Ensemble:\n",
      "--------------------------------------------------\n",
      "Accuracy: 74.4% (0.744)\n",
      "AUC:      85.2% (0.852)\n",
      "\n",
      "Confusion Matrix:\n",
      "              SNII  SNIa\n",
      "Actual SNII    80    30\n",
      "       SNIa    25    80\n",
      "\n",
      "âœ“ Results saved: ../results/plasticc_classical_results_2k.json\n",
      "\n",
      "======================================================================\n",
      "CLASSICAL TRAINING COMPLETE!\n",
      "======================================================================\n",
      "Next step: Train quantum model with top 3 features\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD FEATURES\n",
    "# ============================================================================\n",
    "\n",
    "DATA_DIR = os.path.join(\"..\", \"data\", \"plasticc\")\n",
    "features_df = pd.read_csv(os.path.join(DATA_DIR, \"transient_features.csv\"))\n",
    "\n",
    "print(f\"Loaded {len(features_df)} samples with {len(features_df.columns)} columns\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(features_df['label'].value_counts())\n",
    "\n",
    "# ============================================================================\n",
    "# PREPARE DATA - USE ALL 16 FEATURES\n",
    "# ============================================================================\n",
    "\n",
    "feature_cols = [\n",
    "    # Magnitude features\n",
    "    \"mag_min\", \"mag_max\", \"mag_mean\", \"mag_std\", \"mag_range\",\n",
    "    # Flux features\n",
    "    \"flux_max\", \"flux_mean\", \"flux_std\",\n",
    "    # Time features\n",
    "    \"time_span\", \"rise_time\", \"decline_time\", \"rise_decline_ratio\",\n",
    "    # Slope features\n",
    "    \"mean_rise_slope\", \"mean_decline_slope\", \"max_slope\",\n",
    "    # Metadata\n",
    "    \"n_points\"\n",
    "]\n",
    "\n",
    "X = features_df[feature_cols].values\n",
    "y_str = features_df['label'].values\n",
    "\n",
    "label_map = {'SNII': 0, 'SNIa': 1}\n",
    "y = np.array([label_map[label] for label in y_str])\n",
    "\n",
    "print(f\"\\nFeature matrix: {X.shape}\")\n",
    "print(f\"Labels: {y.shape}, distribution: {np.unique(y, return_counts=True)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# TRAIN-TEST SPLIT\n",
    "# ============================================================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain: {X_train.shape[0]}, Test: {X_test.shape[0]}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SCALE FEATURES\n",
    "# ============================================================================\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ============================================================================\n",
    "# TRAIN MODELS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRAINING CLASSICAL MODELS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "models = {}\n",
    "\n",
    "# Logistic Regression\n",
    "print(\"\\n1. Logistic Regression...\")\n",
    "lr = LogisticRegression(max_iter=2000, C=2.0, random_state=42)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "models['Logistic Regression'] = lr\n",
    "\n",
    "# Random Forest\n",
    "print(\"2. Random Forest...\")\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=600,\n",
    "    max_depth=20,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "models['Random Forest'] = rf\n",
    "\n",
    "# CatBoost\n",
    "print(\"3. CatBoost...\")\n",
    "cb = CatBoostClassifier(\n",
    "    iterations=800,\n",
    "    depth=8,\n",
    "    learning_rate=0.05,\n",
    "    random_state=42,\n",
    "    verbose=False\n",
    ")\n",
    "cb.fit(X_train, y_train)\n",
    "models['CatBoost'] = cb\n",
    "\n",
    "# Ensemble\n",
    "print(\"4. Ensemble (Voting)...\")\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', lr),\n",
    "        ('rf', rf),\n",
    "        ('cb', cb)\n",
    "    ],\n",
    "    voting='soft',\n",
    "    weights=[1, 2, 3]\n",
    ")\n",
    "ensemble.fit(X_train_scaled, y_train)\n",
    "models['Ensemble'] = ensemble\n",
    "\n",
    "# ============================================================================\n",
    "# EVALUATE ALL MODELS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CLASSICAL MODEL RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Use scaled features for LR and Ensemble, raw for RF and CB\n",
    "    if name in ['Logistic Regression', 'Ensemble']:\n",
    "        X_test_input = X_test_scaled\n",
    "    else:\n",
    "        X_test_input = X_test\n",
    "    \n",
    "    y_pred = model.predict(X_test_input)\n",
    "    y_proba = model.predict_proba(X_test_input)[:, 1]\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.1%} ({acc:.3f})\")\n",
    "    print(f\"AUC:      {auc:.1%} ({auc:.3f})\")\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"              SNII  SNIa\")\n",
    "    print(f\"Actual SNII   {cm[0,0]:3d}   {cm[0,1]:3d}\")\n",
    "    print(f\"       SNIa   {cm[1,0]:3d}   {cm[1,1]:3d}\")\n",
    "    \n",
    "    results[name] = {\n",
    "        'accuracy': float(acc),\n",
    "        'auc': float(auc),\n",
    "        'confusion_matrix': cm.tolist()\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "RESULTS_DIR = os.path.join(\"..\", \"results\")\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "results_path = os.path.join(RESULTS_DIR, \"plasticc_classical_results_2k.json\")\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ“ Results saved: {results_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CLASSICAL TRAINING COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Next step: Train quantum model with top 3 features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "298e1d35-b885-4b3c-a4d4-72c6b90940ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FEATURE CORRELATION WITH LABEL (SNIa vs SNII)\n",
      "======================================================================\n",
      "\n",
      "Features ranked by correlation strength:\n",
      "           feature  correlation  correlation_signed      p_value\n",
      "         time_span     0.280059           -0.280059 9.061588e-21\n",
      "      decline_time     0.268915           -0.268915 3.248802e-19\n",
      "           mag_max     0.150529            0.150529 7.382729e-07\n",
      "           mag_std     0.142485            0.142485 2.818433e-06\n",
      "          mag_mean     0.133558            0.133558 1.146827e-05\n",
      "         mag_range     0.104832            0.104832 5.864396e-04\n",
      "         rise_time     0.096462           -0.096462 1.567008e-03\n",
      "mean_decline_slope     0.063565            0.063565 3.744478e-02\n",
      "         flux_mean     0.041182           -0.041182 1.778611e-01\n",
      "           mag_min     0.033363            0.033363 2.750981e-01\n",
      "         max_slope     0.030928           -0.030928 3.116943e-01\n",
      "          n_points     0.021755            0.021755 4.767484e-01\n",
      "          flux_max     0.020245           -0.020245 5.078841e-01\n",
      "rise_decline_ratio     0.017163            0.017163 5.745721e-01\n",
      "          flux_std     0.014076           -0.014076 6.452634e-01\n",
      "   mean_rise_slope     0.002060           -0.002060 9.462861e-01\n",
      "\n",
      "======================================================================\n",
      "ðŸŽ¯ TOP 3 FEATURES FOR QUANTUM: ['time_span', 'decline_time', 'mag_max']\n",
      "======================================================================\n",
      "\n",
      "Class separation check:\n",
      "\n",
      "time_span:\n",
      "  SNIa: mean=71.786, std=43.356\n",
      "  SNII: mean=114.155, std=92.194\n",
      "  Separation: 42.369 (0.46 Ïƒ)\n",
      "\n",
      "decline_time:\n",
      "  SNIa: mean=58.290, std=43.995\n",
      "  SNII: mean=98.044, std=89.706\n",
      "  Separation: 39.754 (0.44 Ïƒ)\n",
      "\n",
      "mag_max:\n",
      "  SNIa: mean=-3.060, std=1.078\n",
      "  SNII: mean=-3.386, std=1.063\n",
      "  Separation: 0.326 (0.31 Ïƒ)\n",
      "\n",
      "âœ“ Saved top 3 features to: ../results/top_3_features.json\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# FEATURE CORRELATION ANALYSIS - FIND TOP 3 FOR QUANTUM\n",
    "# ============================================================================\n",
    "\n",
    "from scipy.stats import pointbiserialr\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FEATURE CORRELATION WITH LABEL (SNIa vs SNII)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Numeric encoding: SNII=0, SNIa=1\n",
    "label_numeric = y\n",
    "\n",
    "correlations = []\n",
    "for i, feat in enumerate(feature_cols):\n",
    "    corr, pval = pointbiserialr(label_numeric, X[:, i])\n",
    "    correlations.append({\n",
    "        'feature': feat,\n",
    "        'correlation': abs(corr),  # absolute value for ranking\n",
    "        'correlation_signed': corr,\n",
    "        'p_value': pval\n",
    "    })\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('correlation', ascending=False)\n",
    "\n",
    "print(\"\\nFeatures ranked by correlation strength:\")\n",
    "print(corr_df.to_string(index=False))\n",
    "\n",
    "# Select TOP 3\n",
    "top_3_features = corr_df.head(3)['feature'].tolist()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"ðŸŽ¯ TOP 3 FEATURES FOR QUANTUM: {top_3_features}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Show class separation for these features\n",
    "print(\"\\nClass separation check:\")\n",
    "for feat in top_3_features:\n",
    "    feat_idx = feature_cols.index(feat)\n",
    "    feat_data = X[:, feat_idx]\n",
    "    \n",
    "    snia_vals = feat_data[y == 1]\n",
    "    snii_vals = feat_data[y == 0]\n",
    "    \n",
    "    print(f\"\\n{feat}:\")\n",
    "    print(f\"  SNIa: mean={snia_vals.mean():.3f}, std={snia_vals.std():.3f}\")\n",
    "    print(f\"  SNII: mean={snii_vals.mean():.3f}, std={snii_vals.std():.3f}\")\n",
    "    print(f\"  Separation: {abs(snia_vals.mean() - snii_vals.mean()):.3f} ({abs(snia_vals.mean() - snii_vals.mean()) / snii_vals.std():.2f} Ïƒ)\")\n",
    "\n",
    "# Save for quantum notebook\n",
    "top_3_path = os.path.join(RESULTS_DIR, \"top_3_features.json\")\n",
    "with open(top_3_path, 'w') as f:\n",
    "    json.dump({'top_3_features': top_3_features}, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ“ Saved top 3 features to: {top_3_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7be4ab-4283-4e8f-a2c9-cea7b3e59e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d315d56c-e8c3-4deb-a373-75375c6db54c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
